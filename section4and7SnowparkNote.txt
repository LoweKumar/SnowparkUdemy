======================
Date - 21/03/2024
======================

Topics covered in snowflake are mentioned below: 
1. Snowpark Write operation
  -Write from s3 to table- json
  -Write from s3 to table - csv
2. Snowpark Copy commands
  -Copy data from s3 to snowflake table
  -Get query id and collect rejected records
  -Copy data from local to snowflake
  
 NOTE : Here in these 2 tasks the stages required are created using AWS Root Key Password not the stage integration object.
 
 Sql query used : 
 create or replace TABLE EMPLOYEE (    FIRST_NAME VARCHAR(16777216),    LAST_NAME VARCHAR(16777216),    EMAIL VARCHAR(16777216),    ADDRESS VARCHAR(16777216),    CITY VARCHAR(16777216),    DOJ DATE);

select * from EMPLOYEE

// Create file format object
CREATE OR REPLACE file format DB1.file_formats.csv_fileformat
    type = csv
    field_delimiter = ','
    skip_header = 1
    null_if = ('NULL','null')
    empty_field_as_null = TRUE;

create or replace storage integration s3_int
  TYPE = EXTERNAL_STAGE
  STORAGE_PROVIDER = S3
  ENABLED = TRUE 
  STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::453859411887:role/snowflakeRole'
  STORAGE_ALLOWED_LOCATIONS = ('s3://snowparkdata/Employee/')
   COMMENT = 'This an optional comment' ;

DESC INTEGRATION s3_int;
    
 // Create stage object with integration object 
CREATE OR REPLACE stage DB1.public.my_s3_stage
    URL = 's3://snowparkdata/Employee/'
    STORAGE_INTEGRATION = s3_int


LIST @DB1.public.my_s3_stage;

create or replace TABLE EMPLOYEE1 (
	FIRST_NAME VARCHAR(16777216),
	LAST_NAME VARCHAR(16777216),
	EMAIL VARCHAR(16777216),
	ADDRESS VARCHAR(16777216),
	CITY VARCHAR(16777216),
	DOJ DATE
);